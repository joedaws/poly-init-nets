# What does training do to the knots?
"""
We know that we can initialize the network to behave like a
a polynomial. We also know that this initialization 
has a particular distribution of knots at points (j/2^n)

- What does training do to the knots?
- Can I visualize the functions that the layers become
"""
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.optim as optim
from deep import DeepNet

# instantiate the network
a = -1
b = 1
L = 7
n = 1
net = DeepNet(L,n,a,b)

# set up the sampling points 
N = 101
x = torch.linspace(-1,1,N)
x = x.reshape(N,1)

# load the learned parameters for the cos example
dat_path = './data/cos_1d_deep_net.pt'
dat_path = './data/x3_1d_deep_unnet.pt'
dat_path = './data/rational_poly_deep_net.pt'
net.load_state_dict(torch.load(dat_path))

print('success in loading learned parameters')
print('Printing first hidden layer biases')
print('\n')
print(net.hidden[0].bias.detach().numpy())

# viusalize first hidden layer outputs
print('Visualizing all four of the functions generated by the first layer')
h1 = net.hidden[0](x).clamp(min=0)

# plot the action of the first layer unit 1
plt.plot(h1[:,0].reshape(N,1).detach().numpy())
plt.title('Unit one of H1')
# plot the action of the first layer unit 2
plt.plot(h1[:,1].reshape(N,1).detach().numpy())
plt.title('Unit two of H1')
# plot the action of the first layer unit 3
plt.plot(h1[:,2].reshape(N,1).detach().numpy())
plt.title('Unit three of H1')
# plot the action of the first layer unit 4
plt.plot(h1[:,3].reshape(N,1).detach().numpy())
plt.title('Unit four of H1')
plt.show()

# set hold
hold = h1

for i in range(1,L):
    print('\n')
    print(net.hidden[i].bias.detach().numpy())
    # move network forward a layer
    hnew = net.hidden[i](hold).clamp(min=0)

    # plot the action of the i-1 layer unit 1
    plt.plot(hnew[:,0].reshape(N,1).detach().numpy())
    plt.title('Unit one of H'+str(i))
    # plot the action of the i-1 layer unit 2
    plt.plot(hnew[:,1].reshape(N,1).detach().numpy())
    plt.title('Unit two of H'+str(i))
    # plot the action of the i-1 layer unit 3
    plt.plot(hnew[:,2].reshape(N,1).detach().numpy())
    plt.title('Unit three of H'+str(i))
    # plot the action of the i-1 layer unit 4
    plt.plot(hnew[:,3].reshape(N,1).detach().numpy())
    plt.title('Unit four of H'+str(i))
    plt.show()

    hold = hnew

# plot final output
hnew = net.hidden[L](hold)
plt.plot(hnew.detach().numpy())
plt.show()

# plot a forward prop
out = net(x)
plt.plot(out.detach().numpy())
plt.show()

